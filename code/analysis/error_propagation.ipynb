{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error propagation with MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "import numba\n",
    "# Library to perform MCMC runs\n",
    "import emcee\n",
    "\n",
    "import mwc_induction_utils as mwc\n",
    "\n",
    "# Useful plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import corner\n",
    "\n",
    "# favorite Seaborn settings for notebooks\n",
    "rc={'lines.linewidth': 2, \n",
    "    'axes.labelsize' : 16, \n",
    "    'axes.titlesize' : 18,\n",
    "    'axes.facecolor' : 'F4F3F6',\n",
    "    'axes.edgecolor' : '000000',\n",
    "    'axes.linewidth' : 1.2,\n",
    "    'xtick.labelsize' : 13,\n",
    "    'ytick.labelsize' : 13,\n",
    "    'grid.linestyle' : ':',\n",
    "    'grid.color' : 'a6a6a6'}\n",
    "sns.set_context('notebook', rc=rc)\n",
    "sns.set_style('darkgrid', rc=rc)\n",
    "sns.set_palette(\"deep\", color_codes=True)\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline (only use with static plots (non-Bokeh))\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Generate a variable with the day that the script is run\n",
    "today = str(datetime.datetime.today().strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the problem\n",
    "\n",
    "In our first parameter estimation [using MCMC](https://github.com/RPGroup-PBoC/mwc_induction/blob/master/code/analysis/MCMC_parameter_estimation.ipynb) we reported a credible region for the MWC parameters and the fold-change based on the data and the fit to the model. But these estimates didn't include previous characterized uncertainty in the parameters of the model.\n",
    "\n",
    "For example at the time we computed the fold-chage for each of the RBS mutants we assumed we knew with 100% certainty the mean repressor copy number. This assumption is far from the truth since in their paper [Garcia and Phillips](http://www.pnas.org/content/108/29/12173.abstract) report the mean $\\pm$ standard deviation of the repressor copy number as revealed by multiple measurements of these quantities. The same applies to the repressor binding energies.\n",
    "\n",
    "The question then becomes how do we include these sources of uncertainty into our fold-change model with induction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes theorem as a method for learning\n",
    "\n",
    "The Bayesian framework gives a natural form on how to solve this issue. Let's focus first on the uncertainty of the repressor. We could write our parameter estimation using Bayes theorem as\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\epsilon_A, \\epsilon_I, R \\mid D, I) \\propto P(D \\mid \\epsilon_A, \\epsilon_I, R, I) \\cdot P(\\epsilon_A, \\epsilon_I, R \\mid I),\n",
    "\\end{equation}\n",
    "\n",
    "where we explicitly included the dependence on the repressor copy number. The second term on the right hand side, the so-called prior, **includes all the information we know before performing the experiment**. For simplicity we can assume that the parameters are independent such that we can rewrite this term as\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\epsilon_A, \\epsilon_I, R \\mid I) = P(\\epsilon_A \\mid I) \\cdot P(\\epsilon_I \\mid I) \\cdot P(R \\mid I).\n",
    "\\end{equation}\n",
    "\n",
    "Usually one doesn't want to bias the inference with the prior, therefore we are train to use *maximally uniformative priors* for the parameters. So for our previous model we chose a Jeffreys' prior for the $\\epsilon_A$ and $\\epsilon_I$ parameteres, i.e.\n",
    "\n",
    "\\begin{align}\n",
    "P(\\epsilon_A \\mid I) &\\propto \\frac{1}{\\epsilon_A}, \\\\\n",
    "P(\\epsilon_I \\mid I) &\\propto \\frac{1}{\\epsilon_I}\n",
    "\\end{align}\n",
    "\n",
    "But in a sense Bayes theorem is a *model for learning*. What we mean with that is that it naturally allows us to update our parameter estimates after performing an experiment and obtaining data. So in the case when one doesn't know anything at all about the parameter value these uniformative priors are the right thing to use. Now, what happens when one does indeed have information about the value of some of these parameters from previous experiments? Well, then that prior information should be included in the prior!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior on the parameters to include sources of uncertainty\n",
    "\n",
    "For the term $P(R \\mid I)$ we should include the characterized uncertainty that Garcia and Phillips reported in their paper. Quoting the paper it reads\n",
    "> Immunoblots were used to measure the number of Lac repressors in six strains with different constitutive levels of Lac repressor. Each value corresponds to an average of cultures grown on at least 3 different days. The error bars are the SD of these measurements.\n",
    "\n",
    "This means that the number they report is the *mean repressor copy number* and the *standard deviation on these measurements*. It is important to clarify that this standard deviation **does not** reflect the single-cell variability of repressors, but the experimental uncertainty when measuring the mean repressor copy number. In other words this standard deviation captures the lack of perfect accuracy when measuring this parameter, not the natural biological noise one expects on a clonal population.\n",
    "\n",
    "The repressor copy number per cell itself is a *discrete variable*, therefore one could naively think that the prior should be therefore given by a discrete distribution. But we should recall that what Garcia and Phillips measured with their immunoblots was not a single cell measurement, but a bulk measurement where they got to measure the **mean repressor copy number** which is not a discrete variable itself. As a matter of fact by the central limit theorem we know that we expect the distribution of the mean repressor copy number to be Gaussian. Therefore we can write\n",
    "\n",
    "\\begin{equation}\n",
    "P(R \\mid \\sigma_R, I) = \\frac{1}{\\sqrt{2 \\pi \\sigma_R^2}}\\exp \\left[ \\frac{(R - R^*)^2}{2 \\sigma_R^2}  \\right],\n",
    "\\end{equation}\n",
    "\n",
    "where $\\sigma_R$ is the characterized standard deviation that Garcia and Phillips experimentally characterized for each RBS mutant, and $R^*$ is the mean repressor level also characterized experimentally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we include this prior for the repressor copy number and an equivalent one for the repressor binding energy, and allow the MCMC walkers to walk on these two new dimensions while fitting the MWC parameters, then the posterior probability for the fold-change would include all of the characterized uncertainty on the parameters! In this way we can properly build the credible region for our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log posterior probability\n",
    "\n",
    "Including the uncertainty on the mean repressor copy number and the binding energy implies that our posterior is now of the form\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\epsilon_A, \\epsilon_I, R_i, \\epsilon_{r_j} \\mid fc_{\\exp_{ijk}}, R_i^*, \\sigma_{R_i}, \\epsilon_{r_j}^*, \\sigma_{\\epsilon_{r_j}}, C_k, I) \\propto \\prod_i \\prod_j \\prod_k P(fc_{\\exp_{ijk}} \\mid \\epsilon_A, \\epsilon_I, R_i, \\epsilon_{r_j}, R_i^*, \\sigma_{R_i}, \\epsilon_{r_j}^*, \\sigma_{\\epsilon_{r_j}}, C_k, I) \\cdot P(\\epsilon_A \\mid C_k, I) \\cdot P(\\epsilon_I \\mid C_k, I) \\cdot P(R_i \\mid R_i^* \\sigma_{R_i}, C_k, I) \\cdot P(\\epsilon_{r_j} \\mid \\epsilon_{r_j}^*, \\sigma_{\\epsilon_{r_j}}, C_k, I),\n",
    "\\end{equation}\n",
    "\n",
    "where the subindex $i$ lists all the RBS mutants, the subindex $j$ lists all the operators, and the subindex $k$ lists all the IPTG concentrations $C$. $fc_{\\exp_{ijk}}$ represents the experimentally determined fold-change.\n",
    "\n",
    "This form of the posterior means that the parameter estimation will be done over the two MWC parameters, however many RBS mutants are included and also however many operators. The independent variables now become:\n",
    "1. The IPTG concentration.\n",
    "2. The experimental mean repressor copy number.\n",
    "3. The experimental standard deviation on the repressor copy number.\n",
    "4. The experimental mean repressor binding energy.\n",
    "5. the experimental standard deviation on the repressor binding enery.\n",
    "\n",
    "The function functional form of the log posterior probability assuming as before a Gaussian distribution of the residuals is of the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\ln P(\\epsilon_A, \\epsilon_I, R_i, \\epsilon_{r_j} \\mid fc_{\\exp_{ijk}}, R_i^*, \\sigma_{R_i}, \\epsilon_{r_j}^*, \\sigma_{\\epsilon_{r_j}}, C_k, \\sigma, I) \\propto - (n + 1) \\ln \\sigma - \\ln \\epsilon_A - \\ln \\epsilon_I + \\sum_i \\sum_j \\sum_k  - \\frac{1}{2 \\sigma^2} \\left(fc_{\\exp_{ijk}} - fc(\\epsilon_A, \\epsilon_I, R_i, \\epsilon_{r_j}, C_k) \\right)^2 - \\frac{\\left( R_i - R_i^* \\right)^2}{2 \\sigma^2_{R_i}} - \\frac{\\left( \\epsilon_{r_j} - \\epsilon_{r_j}^* \\right)^2}{2 \\sigma^2_{\\epsilon_{r_j}}} ,\n",
    "\\end{equation}\n",
    "\n",
    "where $n$ is the total number of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to minimize the data frame parsing that the log-posterior has to do when performing the MCMC let's write a pre-processing function that will parse the data once such that the output can be feed to the log-posterior function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mcmc_pre_process(df):\n",
    "    \"\"\"\n",
    "    Pre-process the tidy DataFrame to prepare it for the MCMC. This is done\n",
    "    separately from the log-posterior calculation to speed up the process\n",
    "    avoiding parsing the DataFrame every evaluation of the posterior.\n",
    "    Parameteres\n",
    "    -----------\n",
    "    df : pandas DataFrame.\n",
    "        A tidy pandas DataFrame as standardized in the project that contains\n",
    "        at least the following columns:\n",
    "        fold_change_A : the experimental fold-change from channel A in the\n",
    "        flow cytometer.\n",
    "        IPTG_uM : uM concentrations of the inducer\n",
    "        repressors : the mean repressor copy number\n",
    "        delta_repressors : the experimental SD on the mean repressor copy number\n",
    "        binding_energy : the mean repressor binding energy\n",
    "        delta_energy : the experimental SD on the binding energy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    [rep_unique, eps_unique] : list.\n",
    "        A list whose first element is the list of the unique mean repressor\n",
    "        copy number found in the DataFrame.\n",
    "        The second element is the list of unique binding energies also found\n",
    "        in the DataFrame.\n",
    "        This is used by the MCMC function to determine how many dimensions \n",
    "        the walkers should walk in.\n",
    "    param_idx : array-like.\n",
    "        An array that indicates in the param array where are each parameters\n",
    "        located. The logic is the following:\n",
    "        In the first 3 positions of the param argument for the MCMC we find\n",
    "        epsilon_A, epsilon_I and sigma the error associated with the Gaussian\n",
    "        likelihood.\n",
    "        After that we have all the repressor copy numbers for each of the RBS\n",
    "        mutants. Followed by all the unique binding energies in the DataFrame.\n",
    "        This variable indicates the position of each of these variables such\n",
    "        that  the function is robust and it works for a DataFrame with 1 RBS \n",
    "        mutant and 1 energy as well as for multiple mutants and multiple enrgies.\n",
    "    data : array-like.\n",
    "        Numpy array pre-arranged in the order that the log-posterior function\n",
    "        expects it with the following columns:\n",
    "        data[:, 0] : fold_change_A\n",
    "        data[:, 1] : IPTG_uM\n",
    "        data[:, 2] : repressors\n",
    "        data[:, 3] : delta_repressors\n",
    "        data[:, 4] : binding_energy\n",
    "        data[:, 5] : delta_energy\n",
    "    \"\"\"\n",
    "    # List the unique variables\n",
    "    rep_unique = np.sort(df.repressors.unique())\n",
    "    eps_unique = np.sort(df.binding_energy.unique())\n",
    "    IPTG_unique = np.sort(df.IPTG_uM.unique())\n",
    "    \n",
    "    # determine the number of unique variables\n",
    "    n_repressor = len(rep_unique)\n",
    "    n_epsilon_r = len(eps_unique)\n",
    "    n_IPTG = len(IPTG_unique)\n",
    "    \n",
    "    # Depending on the number of parameters determine the indexes of the\n",
    "    # parameters to fit\n",
    "    param_idx = np.cumsum([3, n_repressor, n_epsilon_r])\n",
    "    \n",
    "    # Sort the data frame such that the log-posterior function can\n",
    "    # automatically compute the log probability with the right parameters\n",
    "    # for each data point\n",
    "    df_sort = df.sort(['repressors', 'binding_energy', 'IPTG_uM'])\n",
    "    data = np.array(df_sort[['fold_change_A', 'IPTG_uM', \n",
    "                             'repressors', 'delta_repressors', \n",
    "                             'binding_energy', 'delta_energy']])\n",
    "    return [rep_unique, eps_unique], param_idx, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the function to compute the likelihood, the prior and the posterior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood(param, param_idx, unique_var, data, epsilon=4.5):\n",
    "    '''\n",
    "    Computes the log-likelihood\n",
    "    Parameters\n",
    "    ----------\n",
    "    param : array-like\n",
    "        Array with the value of all the parameters/dismensions on which the\n",
    "        MCMC walkers should walk. The array follows this order:\n",
    "        ea, ei, sigma : first 3 columns.\n",
    "        repressor copy number : next columns.\n",
    "        binding energies : final columns.\n",
    "        The exact position of each of these parameters depends on the number\n",
    "        of unique repressors and energies as indicated by param_idx.\n",
    "    param_idx : array-like.\n",
    "        An array that indicates in the param array where are each parameters\n",
    "        located. The logic is the following:\n",
    "        In the first 3 positions of the param argument for the MCMC we find\n",
    "        epsilon_A, epsilon_I and sigma the error associated with the Gaussian\n",
    "        likelihood.\n",
    "        After that we have all the repressor copy numbers for each of the RBS\n",
    "        mutants. Followed by all the unique binding energies in the DataFrame.\n",
    "        This variable indicates the position of each of these variables such\n",
    "        that  the function is robust and it works for a DataFrame with 1 RBS \n",
    "        mutant and 1 energy as well as for multiple mutants and multiple enrgies.\n",
    "    unique_var : : list.\n",
    "        A list whose first element is the list of the unique mean repressor\n",
    "        copy number found in the DataFrame.\n",
    "        The second element is the list of unique binding energies also found\n",
    "        in the DataFrame.\n",
    "        This is used by the MCMC function to determine how many dimensions \n",
    "        the walkers should walk in.\n",
    "    data : array-like.\n",
    "        Numpy array pre-arranged in the order that the log-posterior function\n",
    "        expects it with the following columns:\n",
    "        data[:, 0] : fold_change_A\n",
    "        data[:, 1] : IPTG_uM\n",
    "        data[:, 2] : repressors\n",
    "        data[:, 3] : delta_repressors\n",
    "        data[:, 4] : binding_energy\n",
    "        data[:, 5] : delta_energy\n",
    "    epsilon : float.\n",
    "        Energetic difference between the active and inactive state.\n",
    "    Returns\n",
    "    -------\n",
    "    log likelihood probability\n",
    "    '''\n",
    "    # unpack parameters\n",
    "    ea, ei, sigma = param[0:param_idx[0]] # MWC parameters\n",
    "    rep = param[param_idx[0]:param_idx[1]] # Repressor copy numbers\n",
    "    eps_r = param[param_idx[1]:param_idx[2]] # Represor energies\n",
    "   \n",
    "    # Initialize the log_likelihood\n",
    "    log_like = 0\n",
    "    # loop through the parameters to fit in order to compute the\n",
    "    # theoretical fold change using the right parameters for each strain\n",
    "    for i, r in enumerate(unique_var[0]):\n",
    "        for j, eps in enumerate(unique_var[1]):\n",
    "            data_block = data[(data[:, 2]==r) & (data[:, 4]==eps), :]\n",
    "            # compute the theoretical fold-change\n",
    "            fc_theory = mwc.fold_change_log(data_block[:, 1],\n",
    "                                            ea, ei, epsilon,\n",
    "                                            rep[i], eps_r[j])\n",
    "            # compute the log likelihood for this block of data\n",
    "            log_like -=  np.sum((fc_theory - data_block[:, 0])**2) / 2 / sigma**2\n",
    "            \n",
    "    return log_like\n",
    "\n",
    "def log_prior(param, param_idx, unique_var, data, epsilon=4.5):\n",
    "    '''\n",
    "    Computes the log-prior probability\n",
    "    Parameters\n",
    "    ----------\n",
    "    param : array-like\n",
    "        Array with the value of all the parameters/dismensions on which the\n",
    "        MCMC walkers should walk. The array follows this order:\n",
    "        ea, ei, sigma : first 3 columns.\n",
    "        repressor copy number : next columns.\n",
    "        binding energies : final columns.\n",
    "        The exact position of each of these parameters depends on the number\n",
    "        of unique repressors and energies as indicated by param_idx.\n",
    "    param_idx : array-like.\n",
    "        An array that indicates in the param array where are each parameters\n",
    "        located. The logic is the following:\n",
    "        In the first 3 positions of the param argument for the MCMC we find\n",
    "        epsilon_A, epsilon_I and sigma the error associated with the Gaussian\n",
    "        likelihood.\n",
    "        After that we have all the repressor copy numbers for each of the RBS\n",
    "        mutants. Followed by all the unique binding energies in the DataFrame.\n",
    "        This variable indicates the position of each of these variables such\n",
    "        that  the function is robust and it works for a DataFrame with 1 RBS \n",
    "        mutant and 1 energy as well as for multiple mutants and multiple enrgies.\n",
    "    unique_var : : list.\n",
    "        A list whose first element is the list of the unique mean repressor\n",
    "        copy number found in the DataFrame.\n",
    "        The second element is the list of unique binding energies also found\n",
    "        in the DataFrame.\n",
    "        This is used by the MCMC function to determine how many dimensions \n",
    "        the walkers should walk in.\n",
    "    data : array-like.\n",
    "        Numpy array pre-arranged in the order that the log-posterior function\n",
    "        expects it with the following columns:\n",
    "        data[:, 0] : fold_change_A\n",
    "        data[:, 1] : IPTG_uM\n",
    "        data[:, 2] : repressors\n",
    "        data[:, 3] : delta_repressors\n",
    "        data[:, 4] : binding_energy\n",
    "        data[:, 5] : delta_energy\n",
    "    epsilon : float.\n",
    "        Energetic difference between the active and inactive state.\n",
    "    Returns\n",
    "    -------\n",
    "    log prior probability\n",
    "    '''\n",
    "    # unpack parameters\n",
    "    ea, ei, sigma = param[0:param_idx[0]] # MWC parameters\n",
    "    rep = param[param_idx[0]:param_idx[1]] # Repressor copy numbers\n",
    "    eps_r = param[param_idx[1]:param_idx[2]] # Represor energies\n",
    "    \n",
    "    # Initialize the log_prior\n",
    "    log_prior = 0\n",
    "    # loop through the parameters to to fit in order to compute the appropiate\n",
    "    # log prior\n",
    "    for i, r in enumerate(unique_var[0]):\n",
    "        for j, eps in enumerate(unique_var[1]):\n",
    "            data_block = data[(data[:, 2]==r) & (data[:, 4]==eps), :]\n",
    "            log_prior -= np.sum((rep[i] - data_block[:, 2])**2 / \\\n",
    "                         2 / data_block[:, 3]**2)\n",
    "            log_prior -= np.sum((eps_r[j] - data_block[:, 4])**2 / \\\n",
    "                         2 / data_block[:, 5]**2)\n",
    "                \n",
    "    # check the bounds on the parameterreps\n",
    "    if np.any(rep <= 0) or (sigma <= 0):\n",
    "        return -np.inf\n",
    "    \n",
    "    return log_prior\n",
    "\n",
    "def log_post(param, param_idx, unique_var, data, epsilon=4.5):\n",
    "    '''\n",
    "    Computes the log posterior probability.\n",
    "    Parameters\n",
    "    ----------\n",
    "    param : array-like\n",
    "        Array with the value of all the parameters/dismensions on which the\n",
    "        MCMC walkers should walk. The array follows this order:\n",
    "        ea, ei, sigma : first 3 columns.\n",
    "        repressor copy number : next columns.\n",
    "        binding energies : final columns.\n",
    "        The exact position of each of these parameters depends on the number\n",
    "        of unique repressors and energies as indicated by param_idx.\n",
    "    param_idx : array-like.\n",
    "        An array that indicates in the param array where are each parameters\n",
    "        located. The logic is the following:\n",
    "        In the first 3 positions of the param argument for the MCMC we find\n",
    "        epsilon_A, epsilon_I and sigma the error associated with the Gaussian\n",
    "        likelihood.\n",
    "        After that we have all the repressor copy numbers for each of the RBS\n",
    "        mutants. Followed by all the unique binding energies in the DataFrame.\n",
    "        This variable indicates the position of each of these variables such\n",
    "        that  the function is robust and it works for a DataFrame with 1 RBS \n",
    "        mutant and 1 energy as well as for multiple mutants and multiple enrgies.\n",
    "    unique_var : : list.\n",
    "        A list whose first element is the list of the unique mean repressor\n",
    "        copy number found in the DataFrame.\n",
    "        The second element is the list of unique binding energies also found\n",
    "        in the DataFrame.\n",
    "        This is used by the MCMC function to determine how many dimensions \n",
    "        the walkers should walk in.\n",
    "    data : array-like.\n",
    "        Numpy array pre-arranged in the order that the log-posterior function\n",
    "        expects it with the following columns:\n",
    "        data[:, 0] : fold_change_A\n",
    "        data[:, 1] : IPTG_uM\n",
    "        data[:, 2] : repressors\n",
    "        data[:, 3] : delta_repressors\n",
    "        data[:, 4] : binding_energy\n",
    "        data[:, 5] : delta_energy\n",
    "    epsilon : float.\n",
    "        Energetic difference between the active and inactive state.\n",
    "    Returns\n",
    "    -------\n",
    "    The log posterior probability\n",
    "    '''\n",
    "    # unpack parameters\n",
    "    ea, ei, sigma = param[0:param_idx[0]] # MWC parameters\n",
    "    rep = param[param_idx[0]:param_idx[1]] # Repressor copy numbers\n",
    "    eps_r = param[param_idx[1]:param_idx[2]] # Represor energies\n",
    "    \n",
    "    lnp = log_prior(param, param_idx, unique_var, data, epsilon)\n",
    "    # Check before computing the likelihood if one of the boundaries set by\n",
    "    # the prior was not satisfied. If that is the case don't waste time\n",
    "    # computing the likelihood and return -i -inf\n",
    "    if lnp == -np.inf:\n",
    "        return lnp\n",
    "    \n",
    "    return -(len(data) + 1) * np.log(sigma)\\\n",
    "            + log_likelihood(param, param_idx, unique_var, data, epsilon)\\\n",
    "            + lnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read the data into a tidy `DataFrame`. We will include the uncertainty on the repressor copy number as determined experimentally by Garcia and Phillips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List the error sources as described by Garcia & Phillips PNAS 2011.\n",
    "delta_R = {'HG104':2, 'RBS1147':10, 'RBS446':15, 'RBS1027':20, 'RBS1':80,\n",
    "               'RBS1L':170}\n",
    "delta_epsilon_r = {'O1':0.2, 'O2':0.2, 'O3':0.1, 'Oid':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique data-sets: 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>operator</th>\n",
       "      <th>binding_energy</th>\n",
       "      <th>rbs</th>\n",
       "      <th>repressors</th>\n",
       "      <th>IPTG_uM</th>\n",
       "      <th>mean_YFP_A</th>\n",
       "      <th>mean_YFP_bgcorr_A</th>\n",
       "      <th>fold_change_A</th>\n",
       "      <th>delta_repressors</th>\n",
       "      <th>delta_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>20160804</td>\n",
       "      <td>mrazomej</td>\n",
       "      <td>O2</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>RBS1L</td>\n",
       "      <td>870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3624.474605</td>\n",
       "      <td>111.851286</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>170</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20160804</td>\n",
       "      <td>mrazomej</td>\n",
       "      <td>O2</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>RBS1</td>\n",
       "      <td>610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3619.786265</td>\n",
       "      <td>107.162946</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>80</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>20160804</td>\n",
       "      <td>mrazomej</td>\n",
       "      <td>O2</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>RBS1027</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3717.019527</td>\n",
       "      <td>204.396208</td>\n",
       "      <td>0.013059</td>\n",
       "      <td>20</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>20160804</td>\n",
       "      <td>mrazomej</td>\n",
       "      <td>O2</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>RBS446</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3854.650585</td>\n",
       "      <td>342.027265</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>20160804</td>\n",
       "      <td>mrazomej</td>\n",
       "      <td>O2</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>RBS1147</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4169.802851</td>\n",
       "      <td>657.179531</td>\n",
       "      <td>0.041988</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      date  username operator  binding_energy      rbs  repressors  \\\n",
       "0      2  20160804  mrazomej       O2           -13.9    RBS1L         870   \n",
       "1      3  20160804  mrazomej       O2           -13.9     RBS1         610   \n",
       "2      4  20160804  mrazomej       O2           -13.9  RBS1027         130   \n",
       "3      5  20160804  mrazomej       O2           -13.9   RBS446          62   \n",
       "4      6  20160804  mrazomej       O2           -13.9  RBS1147          30   \n",
       "\n",
       "   IPTG_uM   mean_YFP_A  mean_YFP_bgcorr_A  fold_change_A  delta_repressors  \\\n",
       "0      0.0  3624.474605         111.851286       0.007146               170   \n",
       "1      0.0  3619.786265         107.162946       0.006847                80   \n",
       "2      0.0  3717.019527         204.396208       0.013059                20   \n",
       "3      0.0  3854.650585         342.027265       0.021853                15   \n",
       "4      0.0  4169.802851         657.179531       0.041988                10   \n",
       "\n",
       "   delta_energy  \n",
       "0           0.2  \n",
       "1           0.2  \n",
       "2           0.2  \n",
       "3           0.2  \n",
       "4           0.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = '../../data/'\n",
    "# read the list of data-sets to ignore\n",
    "data_ignore = pd.read_csv(datadir + 'datasets_ignore.csv', header=None).values\n",
    "# read the all data sets except for the ones in the ignore list\n",
    "all_files = glob.glob(datadir + '*' + '_IPTG_titration' + '*csv')\n",
    "ignore_files = [f for f in all_files for i in data_ignore if i[0] in f]\n",
    "read_files = [f for f in all_files if f not in ignore_files]\n",
    "print('Number of unique data-sets: {:d}'.format(len(read_files)))\n",
    "df = pd.concat(pd.read_csv(f, comment='#') for f in read_files)\n",
    "\n",
    "# Now we remove the autofluorescence and delta values\n",
    "df = df[(df.rbs != 'auto') & (df.rbs != 'delta')]\n",
    "# Restart index\n",
    "df = df.reset_index()\n",
    "\n",
    "# Add the error columns to the data frame\n",
    "df['delta_repressors'] = pd.Series([delta_R[df.iloc[x].rbs] for x\\\n",
    "                                    in np.arange(df.shape[0])])\n",
    "df['delta_energy'] = pd.Series([delta_epsilon_r[x] for x in df.operator])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing walkers automatically.\n",
    "\n",
    "To make the function more robust we will define a function that initializes the MCMC walkers nearby the MAP for the MWC parameters. The function first finds the MAP using the [non-linear regression](https://github.com/RPGroup-PBoC/mwc_induction/blob/master/code/analysis/non_linear_regression.ipynb) function we previously defined, and starts the walkers around that region. Then it initializes the walkers for the mean repressor copy number and the binding energy also around the MAP value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_walkers(df, n_walkers, unique_var, param_idx):\n",
    "    '''\n",
    "    Initialize walkers according to however many dimensions will be explored\n",
    "    by the MCMC\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame.\n",
    "        Data frame containing the data that will be used for fitting the\n",
    "        parameters\n",
    "    n_walkers : int.\n",
    "        Number of walkers for the MCMC.\n",
    "    unique_var : : list.\n",
    "        A list whose first element is the list of the unique mean repressor\n",
    "        copy number found in the DataFrame.\n",
    "        The second element is the list of unique binding energies also found\n",
    "        in the DataFrame.\n",
    "        This is used by the MCMC function to determine how many dimensions \n",
    "        the walkers should walk in.\n",
    "    param_idx : array-like.\n",
    "        An array that indicates in the param array where are each parameters\n",
    "        located. The logic is the following:\n",
    "        In the first 3 positions of the param argument for the MCMC we find\n",
    "        epsilon_A, epsilon_I and sigma the error associated with the Gaussian\n",
    "        likelihood.\n",
    "        After that we have all the repressor copy numbers for each of the RBS\n",
    "        mutants. Followed by all the unique binding energies in the DataFrame.\n",
    "        This variable indicates the position of each of these variables such\n",
    "        that  the function is robust and it works for a DataFrame with 1 RBS \n",
    "        mutant and 1 energy as well as for multiple mutants and multiple enrgies.\n",
    "    n_dim : int.\n",
    "        Number of dimensions that the MCMC walkers will walk on.\n",
    "    Returns\n",
    "    -------\n",
    "    '''\n",
    "    #Define the parameters for emcee\n",
    "    n_dim = 3 + np.sum([len(x) for x in unique_var])\n",
    "    \n",
    "    # Perform a non-linear regression\n",
    "    map_param =  mwc.non_lin_reg_mwc(df, p0=[1, 7], diss_const=False)\n",
    "    mean = [map_param[0], map_param[2]]\n",
    "    cov = np.array([[map_param[1], 0], [0, map_param[3]]])\n",
    "    \n",
    "    # Initialize walkers\n",
    "    p0 = np.empty((n_walkers, n_dim))\n",
    "    # Initialize walkers\n",
    "    p0 = np.empty((n_walkers, n_dim))\n",
    "    p0[:,[0, 1]] = np.random.multivariate_normal(mean, cov, n_walkers)# ea, ei\n",
    "    p0[:,2] = np.random.uniform(1E-5, 0.2, n_walkers)# sigma\n",
    "    \n",
    "    # loop through the repressors\n",
    "    for i, r in enumerate(unique_var[0]):\n",
    "        sigma_r = df[df.repressors==r].delta_repressors.unique()\n",
    "        p0[:, param_idx[0]+i] = np.random.normal(r, sigma_r, n_walkers)\n",
    "    for j, eps in enumerate(unique_var[1]):\n",
    "        sigma_eps = df[df.binding_energy==eps].delta_energy.unique()\n",
    "        p0[:, param_idx[1]+j] = np.random.normal(eps, sigma_eps, n_walkers)\n",
    "    \n",
    "    return p0, n_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC on the RBS1027 data.\n",
    "Let's first test the functions fitting for the RBS1027 strain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rbs = df[df.rbs=='RBS1027']\n",
    "\n",
    "# Preprocess the data\n",
    "unique_var, param_idx, data = mcmc_pre_process(rbs)\n",
    "\n",
    "# initialize the walkers\n",
    "n_walkers = 100\n",
    "n_burn = 500\n",
    "n_steps = 5000\n",
    "p0, n_dim = init_walkers(rbs, n_walkers, unique_var, param_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Call the sampler. \n",
    "sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_post,\\\n",
    "                args=(param_idx, unique_var, data, 4.5),\\\n",
    "                threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do the burn in \n",
    "pos, prob, state = sampler.run_mcmc(p0, n_burn, storechain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = True\n",
    "if sample:\n",
    "    # Perform the real MCMC\n",
    "    _ = sampler.run_mcmc(pos, n_steps)\n",
    "    output = open('../../data/mcmc/' + today + \\\n",
    "                  '_error_prop_RBS1027.pkl', 'wb')\n",
    "    pickle.dump(sampler.flatchain, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the flat-chain\n",
    "with open('../../data/mcmc/' + '20160820' + \\\n",
    "                  '_error_prop_RBS1027.pkl', 'rb') as file:\n",
    "    unpickler = pickle.Unpickler(file)\n",
    "    gauss_flatchain = unpickler.load()\n",
    "\n",
    "# Draw the corner plot\n",
    "fig = corner.corner(gauss_flatchain, bins=50, plot_contours=True,\n",
    "                   labels=[r'$\\epsilon_A$', r'$\\epsilon_I$', \n",
    "                           r'$\\sigma$', r'$R$', r'$\\Delta \\epsilon_r$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the flat-chain\n",
    "with open('../../data/mcmc/' + '20160820' + \\\n",
    "                  '_error_prop_RBS1027.pkl', 'rb') as file:\n",
    "    unpickler = pickle.Unpickler(file)\n",
    "    gauss_flatchain = unpickler.load()\n",
    "    \n",
    "# map value of the MWC parameters\n",
    "ea, ei = np.mean(gauss_flatchain[:, [0, 1]], axis=0)\n",
    "Ka, Ki = np.exp(-ea), np.exp(-ei)\n",
    "# ea range\n",
    "ea_hpd = mwc.hpd(gauss_flatchain[:, 0], 0.95)\n",
    "ei_hpd = mwc.hpd(gauss_flatchain[:, 1], 0.95)\n",
    "Ka_hpd = np.exp(-ea_hpd)\n",
    "Ki_hpd = np.exp(-ei_hpd)\n",
    "\n",
    "# Print results\n",
    "print(\"\"\"\n",
    "The most probable parameters for the MWC model\n",
    "----------------------------------------------\n",
    "Ka = {0:.2f} +{1:0.3f} -{2:0.3f} uM\n",
    "Ki = {3:.5f} +{4:0.6f} -{5:0.6f} uM\n",
    "\"\"\".format(Ka, np.abs(Ka-Ka_hpd[0]), np.abs(Ka-Ka_hpd[1]),\\\n",
    "           Ki,np.abs(Ki-Ki_hpd[0]), np.abs(Ki-Ki_hpd[1])))\n",
    "\n",
    "# map value of the re-fit repressor and binding energy\n",
    "R, epsilon_r = np.mean(gauss_flatchain[:, [3, 4]], axis=0)\n",
    "# R range\n",
    "R_hpd = mwc.hpd(gauss_flatchain[:, 3], 0.95)\n",
    "# epsilon_r range\n",
    "epsilon_hpd = mwc.hpd(gauss_flatchain[:, 4], 0.95)\n",
    "\n",
    "# Print the results\n",
    "print('''\n",
    "The re-fit repressor copy number and energy\n",
    "-------------------------------------------\n",
    "R = {0:.2f} +{1:0.3f} -{2:0.3f} repressors / cell\n",
    "epsilon_r = {3:.5f} +{4:0.6f} -{5:0.6f} kBT\n",
    "'''.format(R, np.abs(R-R_hpd[0]), np.abs(R-R_hpd[1]),\\\n",
    "           epsilon_r,np.abs(epsilon_r-epsilon_hpd[0]),\\\n",
    "                     np.abs(epsilon_r-epsilon_hpd[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the MCMC with all the O2 data\n",
    "\n",
    "Having tested the functions we can now proceed to perform the MCMC using all the O2 strains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "unique_var, param_idx, data = mcmc_pre_process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_walkers = 50\n",
    "n_burn = 500\n",
    "n_steps = 8000\n",
    "p0, n_dim = init_walkers(df, n_walkers, unique_var, param_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Call the sampler. \n",
    "sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_post,\\\n",
    "                args=(param_idx, unique_var, data, 4.5),\\\n",
    "                threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = False\n",
    "if sample:\n",
    "    #Do the burn in\n",
    "    print('Performing the burn-in')\n",
    "    pos, prob, state = sampler.run_mcmc(p0, n_burn, storechain=False)\n",
    "    # Perform the real MCMC\n",
    "    print('Performing the MCMC')\n",
    "    _ = sampler.run_mcmc(pos, n_steps)\n",
    "    output = open('../../data/mcmc/' + today + \\\n",
    "                  '_error_prop_pool_data.pkl', 'wb')\n",
    "    pickle.dump(sampler.flatchain, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the flat-chain\n",
    "with open('../../data/mcmc/' + '20160827' + \\\n",
    "                  '_error_prop_pool_data.pkl', 'rb') as file:\n",
    "    unpickler = pickle.Unpickler(file)\n",
    "    gauss_flatchain = unpickler.load()\n",
    "\n",
    "# Draw the corner plot\n",
    "fig = corner.corner(gauss_flatchain, bins=50, plot_contours=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(gauss_flatchain, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = np.concatenate([['ea', 'ei', 'sigma'],\\\n",
    "          [df[df.repressors==r].rbs.unique()[0] for r in unique_var[0]],\n",
    "          [df[df.binding_energy==o].operator.unique()[0] for o in unique_var[1]]])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmc_df = pd.DataFrame(gauss_flatchain, columns=columns)\n",
    "mcmc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Running the MCMC with less constrained priors\n",
    "\n",
    "An interesting feature to explore is to see \"how well we could fit the data\" given that we truly allow all the parameters to be fit. We can simply do that by extending the $\\sigma$ value on the priors for the repressor copy numbers and the binding energies. In this example we will try multiplying the error that Hernan and Phillips originally infered from their data by a factor of 2-10.\n",
    "\n",
    "Let's read the data and define this larger error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique data-sets: 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repressors</th>\n",
       "      <th>delta_repressors</th>\n",
       "      <th>binding_energy</th>\n",
       "      <th>delta_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>870</td>\n",
       "      <td>850</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>610</td>\n",
       "      <td>400</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   repressors  delta_repressors  binding_energy  delta_energy\n",
       "0         870               850           -13.9           3.0\n",
       "1         610               400           -13.9           3.0\n",
       "2         130               100           -13.9           3.0\n",
       "3          62                75           -13.9           3.0\n",
       "4          30                50           -13.9           3.0\n",
       "5          11                10           -13.9           3.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = '../../data/'\n",
    "# read the list of data-sets to ignore\n",
    "data_ignore = pd.read_csv(datadir + 'datasets_ignore.csv', header=None).values\n",
    "# read the all data sets except for the ones in the ignore list\n",
    "all_files = glob.glob(datadir + '*' + '_IPTG_titration' + '*csv')\n",
    "ignore_files = [f for f in all_files for i in data_ignore if i[0] in f]\n",
    "read_files = [f for f in all_files if f not in ignore_files]\n",
    "print('Number of unique data-sets: {:d}'.format(len(read_files)))\n",
    "df = pd.concat(pd.read_csv(f, comment='#') for f in read_files)\n",
    "\n",
    "# Now we remove the autofluorescence and delta values\n",
    "df = df[(df.rbs != 'auto') & (df.rbs != 'delta')]\n",
    "# Restart index\n",
    "df = df.reset_index()\n",
    "\n",
    "#Define increased error\n",
    "error_r = 5\n",
    "error_e = 15\n",
    "# Add the error columns to the data frame\n",
    "df['delta_repressors'] = pd.Series([delta_R[df.iloc[x].rbs] * error_r for x\\\n",
    "                                    in np.arange(df.shape[0])])\n",
    "df['delta_energy'] = pd.Series([delta_epsilon_r[x] * error_e for x in df.operator])\n",
    "\n",
    "df[['repressors', 'delta_repressors', 'binding_energy', 'delta_energy']].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/razo/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:66: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "unique_var, param_idx, data = mcmc_pre_process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_walkers = 50\n",
    "n_burn = 8000\n",
    "n_steps = 15000\n",
    "p0, n_dim = init_walkers(df, n_walkers, unique_var, param_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Call the sampler. \n",
    "sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_post,\\\n",
    "                args=(param_idx, unique_var, data, 4.5),\\\n",
    "                threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing the burn-in\n",
      "Performing the MCMC\n"
     ]
    }
   ],
   "source": [
    "sample = True\n",
    "if sample:\n",
    "    #Do the burn in\n",
    "    print('Performing the burn-in')\n",
    "    pos, prob, state = sampler.run_mcmc(p0, n_burn, storechain=False)\n",
    "    # Perform the real MCMC\n",
    "    print('Performing the MCMC')\n",
    "    _ = sampler.run_mcmc(pos, n_steps)\n",
    "    output = open('../../data/mcmc/' + today + \\\n",
    "                  '_error_prop_pool_data_larger_sigma.pkl', 'wb')\n",
    "    pickle.dump(sampler.flatchain, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ea          -5.281887\n",
       "ei           0.335814\n",
       "sigma        0.071112\n",
       "HG104        9.987720\n",
       "RBS1147     36.121439\n",
       "RBS446      64.764863\n",
       "RBS1027    127.357285\n",
       "RBS1       576.111096\n",
       "RBS1L      783.607079\n",
       "O1         -15.379752\n",
       "O2         -13.690906\n",
       "O3          -9.485899\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the flat-chain\n",
    "with open('../../data/mcmc/' + '20160905' + \\\n",
    "                  '_error_prop_pool_data_larger_sigma.pkl', 'rb') as file:\n",
    "    unpickler = pickle.Unpickler(file)\n",
    "    gauss_flatchain = unpickler.load()\n",
    "    \n",
    "# Generate a Pandas Data Frame with the mcmc chain\n",
    "columns = np.concatenate([['ea', 'ei', 'sigma'],\\\n",
    "          [df[df.repressors==r].rbs.unique()[0] for r in \\\n",
    "              np.sort(df.repressors.unique())],\n",
    "          [df[df.binding_energy==o].operator.unique()[0] for o in \\\n",
    "              np.sort(df.binding_energy.unique())]])\n",
    "\n",
    "mcmc_df = pd.DataFrame(gauss_flatchain, columns=columns)\n",
    "mcmc_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
