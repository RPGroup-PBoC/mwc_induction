{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6557f48d97f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Suppress future warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "\n",
    "import numdifftools as ndt # to comput the Hessian matrix\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables high res graphics inline (only use with static plots (non-Bokeh))\n",
    "# SVG is preferred, but there is a bug in Jupyter with vertical lines\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "rc={'lines.linewidth': 2, \n",
    "    'axes.labelsize' : 16, \n",
    "    'axes.titlesize' : 18,\n",
    "    'axes.facecolor' : 'F4F3F6',\n",
    "    'axes.edgecolor' : '000000',\n",
    "    'axes.linewidth' : 1.2,\n",
    "    'xtick.labelsize' : 13,\n",
    "    'ytick.labelsize' : 13,\n",
    "    'grid.linestyle' : ':',\n",
    "    'grid.color' : 'a6a6a6'}\n",
    "\n",
    "sns.set_context('notebook', rc=rc)\n",
    "sns.set_style('darkgrid', rc=rc)\n",
    "sns.set_palette(\"deep\", color_codes=True)\n",
    "\n",
    "# Suppress future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear regression.\n",
    "\n",
    "In order to obtain the MWC parameters given the fold-change measurements Manuel took at MBL and a credible region on such parameters we will use a Bayesian approach to perform a non-linear regression.\n",
    "Our theoretical model dictates that the fold change in gene expression is given by\n",
    "\\begin{equation}\n",
    "    fc = \\frac{1}{1 + \\frac{2R p_{act}(C)}{N_{NS}} \\left( 1 + e^{-\\beta \\Delta \\epsilon_{ai}} \\right)  e^{-\\beta \\Delta \\epsilon_r}},\n",
    "\\end{equation}\n",
    "where $p_{act}(C)$ is given by\n",
    "\\begin{equation}\n",
    "    p_{act}(C) = \\frac{\\left( 1 + C e^{\\epsilon_A}\\right)^2}{\\left( 1 + C e^{\\epsilon_A}\\right)^2 + e^{-\\beta \\epsilon_{ai}} \\left( 1 + C e^{\\epsilon_I}\\right)^2}.\n",
    "\\end{equation}\n",
    "\n",
    "We define $\\epsilon_A = -\\ln K_A$ and $\\epsilon_I = -\\ln K_I$ for convenience during the regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to fit the parameters $\\epsilon_A$ and $\\epsilon_I$ by Bayes theorem we have that\n",
    "\\begin{equation}\n",
    "P(\\epsilon_A, \\epsilon_I \\mid D, I) \\propto P(D \\mid \\epsilon_A, \\epsilon_I, I) \\cdot P(\\epsilon_A, \\epsilon_I \\mid I),\n",
    "\\end{equation}\n",
    "where $D$ is the experimental data and $I$ is all the previous information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian likelihood and constant error\n",
    "\n",
    "The simplest model to perform the regression is to assume the following:\n",
    "1. each measurement is independent\n",
    "2. the errors are Gaussian distributed\n",
    "3. this error is constant along the range of IPTG.\n",
    "\n",
    "This third assumption can be relaxed further down the road, but for now this is the easiest zero-order approximation we want to implement.\n",
    "\n",
    "Now it is important to indicate that each element lf $D$ is a \"pair\" of a dependent variable (the experimental fold change $fc_{exp}$) and the independent variables (the repressor copy number $R$, the binding energy $\\Delta \\epsilon_r$ and the IPTG concentration $C$). With this in hand we implement the first assumption as\n",
    "\\begin{equation}\n",
    "P(D \\mid \\epsilon_A, \\epsilon_I, I) = \\prod_{i = 1}^n P(fc_{exp}^{(i)} \\mid \\epsilon_A, \\epsilon_I, R^{(i)}, \\Delta\\epsilon_r^{(i)}, C^{(i)}, I),\n",
    "\\end{equation}\n",
    "where $n$ is the number of data points and the superscript $(i)$ indicates the $i$th element of $D$.\n",
    "\n",
    "Implementing the second and third assumption we obtain\n",
    "\\begin{equation}\n",
    "P(D \\mid \\epsilon_A, \\epsilon_I, \\sigma, I) = \\left( 2\\pi\\sigma^2 \\right)^{-\\frac{n}{2}} \\prod_{i = 1}^n \\exp \\left[ \\frac{1}{2 \\sigma^2} \\left( fc_{exp}^{(i)} - fc\\left(\\epsilon_A, \\epsilon_I, R^{(i)}, \\Delta\\epsilon_r^{(i)}, C^{(i)} \\right) \\right)^2 \\right],\n",
    "\\end{equation}\n",
    "where we include the parameter $\\sigma$ associated with the Gaussian distributed error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the priors we can assume that the 3 parameters $\\epsilon_A, \\epsilon_I$ and $\\sigma$ are not only independent, but since they have a uniform prior in log scale they can have a Jeffres' prior, i.e.\n",
    "\\begin{equation}\n",
    "P(\\epsilon_A, \\epsilon_I, \\sigma \\mid I) \\equiv \\frac{1}{\\epsilon_A}\\cdot\\frac{1}{\\epsilon_I}\\cdot\\frac{1}{\\sigma}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all the pieces together we can compute the posterior distribution as\n",
    "\\begin{equation}\n",
    "P(\\epsilon_A, \\epsilon_I, \\sigma \\mid D, I) \\propto \\left( 2\\pi\\sigma^2 \\right)^{-\\frac{n}{2}} \\prod_{i = 1}^n \\exp \\left[ \\frac{1}{2 \\sigma^2} \\left( fc_{exp}^{(i)} - fc\\left(\\epsilon_A, \\epsilon_I, R^{(i)}, \\Delta\\epsilon_r^{(i)}, C^{(i)} \\right) \\right)^2 \\right] \\frac{1}{\\epsilon_A}\\cdot\\frac{1}{\\epsilon_I}\\cdot\\frac{1}{\\sigma}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we are left with the nuance parameter $\\sigma$ that we don't care about. To eliminate this parameter we need to marginalize over all values of $\\sigma$ as\n",
    "\\begin{equation}\n",
    "P(\\epsilon_A, \\epsilon_I \\mid D, I) = \\int_{- \\infty}^\\infty d\\sigma P(\\epsilon_A, \\epsilon_I, \\sigma \\mid D, I).\n",
    "\\end{equation}\n",
    "And when everything settles down, i.e. after some nasty integration, we find that the posterior is given by the student-t distribution\n",
    "\\begin{equation}\n",
    "P(\\epsilon_A, \\epsilon_I \\mid D, I) \\propto \\left[ \\sum_{i=1}^n \\left( fc_{exp}^{(i)} - fc\\left(\\epsilon_A, \\epsilon_I, R^{(i)}, \\Delta\\epsilon_r^{(i)}, C^{(i)} \\right) \\right)^2 \\right]^{\\frac{n}{2}}. \n",
    "\\end{equation}\n",
    "\n",
    "To work with the log posterior probability we have that\n",
    "\\begin{equation}\n",
    "\\ln P(\\epsilon_A, \\epsilon_I \\mid D, I) \\propto \\frac{n}{2} \\ln \\left[ \\sum_{i=1}^n \\left( fc_{exp}^{(i)} - fc\\left(\\epsilon_A, \\epsilon_I, R^{(i)}, \\Delta\\epsilon_r^{(i)}, C^{(i)} \\right) \\right)^2 \\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code up the functions to compute the theoretical fold-change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a funciton to compute the fold change as a funciton of IPTG\n",
    "def pact(IPTG, ea, ei, epsilon=4.5):\n",
    "    '''\n",
    "    Returns the probability of a repressor being active as described by the MWC\n",
    "    model.\n",
    "    Parameter\n",
    "    ---------\n",
    "    IPTG : array-like.\n",
    "        concentrations of inducer on which to evaluate the function\n",
    "    ea, ei : float.\n",
    "        minus log of the dissociation constants of the active and the inactive \n",
    "        states respectively\n",
    "    epsilon : float.\n",
    "        energy difference between the active and the inactive state\n",
    "    Returns\n",
    "    -------\n",
    "    pact : float.\n",
    "        probability of a repressor of being in the active state. Active state is\n",
    "        defined as the state that can bind to the DNA.\n",
    "    '''\n",
    "    pact = (1 + IPTG * np.exp(ea))**2 / \\\n",
    "    ((1 + IPTG * np.exp(ea))**2 + np.exp(-epsilon) * (1 + IPTG * np.exp(ei))**2)\n",
    "    return pact\n",
    "\n",
    "def fold_change(IPTG, ea, ei, epsilon, R, epsilon_r):\n",
    "    '''\n",
    "    Returns the gene expression fold change according to the thermodynamic model\n",
    "    with the extension that takes into account the effect of the inducer.\n",
    "    Parameter\n",
    "    ---------\n",
    "    IPTG : array-like.\n",
    "        concentrations of inducer on which to evaluate the function\n",
    "    ea, ei : float.\n",
    "        minus log of the dissociation constants of the active and the inactive \n",
    "        states respectively\n",
    "    epsilon : float.\n",
    "        energy difference between the active and the inactive state\n",
    "    R : array-like.\n",
    "        repressor copy number for each of the strains. The length of this array\n",
    "        should be equal to the IPTG array. If only one value of the repressor is\n",
    "        given it is asssume that all the data points should be evaluated with\n",
    "        the same repressor copy number\n",
    "    epsilon_r : array-like\n",
    "        repressor binding energy. The length of this array\n",
    "        should be equal to the IPTG array. If only one value of the binding\n",
    "        energy is given it is asssume that all the data points \n",
    "        should be evaluated with the same repressor copy number\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fold-change : float.\n",
    "        gene expression fold change as dictated by the thermodynamic model.\n",
    "   '''\n",
    "    return 1 / (1 + 2 * R / 5E6 * pact(IPTG, ea, ei, epsilon) * \\\n",
    "            (1 + np.exp(-epsilon)) * np.exp(-epsilon_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's code up the log posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_post(param, indep_var, dep_var):\n",
    "    '''\n",
    "    Computes the log posterior for a single set of parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    param : array-like.\n",
    "        param[0] = epsilon_a\n",
    "        ]aram[1] = epsilon_i\n",
    "    indep_var : n x 3 array.\n",
    "        series of independent variables to compute the theoretical fold-change.\n",
    "        1st column : IPTG concentration\n",
    "        2nd column : repressor copy number\n",
    "        3rd column : repressor binding energy\n",
    "    dep_var : array-like\n",
    "        dependent variable, i.e. experimental fold-change. Then length of this\n",
    "        array should be the same as the number of rows in indep_var.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    log_post : float.\n",
    "        the log posterior probability\n",
    "    '''\n",
    "    # unpack parameters\n",
    "    ea, ei = param\n",
    "    \n",
    "    # unpack independent variables\n",
    "    IPTG, R, epsilon_r = indep_var[:, 0], indep_var[:, 1], indep_var[:, 2]\n",
    "    \n",
    "    # compute the theoretical fold-change\n",
    "    fc_theory = fold_change(IPTG, ea, ei, 4.5, R, epsilon_r)\n",
    "    \n",
    "    # return the log posterior\n",
    "    return -len(dep_var) / 2 * np.log(np.sum((dep_var - fc_theory)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the functions with only 1 strain and one operator \n",
    "\n",
    "Now it is time to test this! But first let's read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the data. \n",
    "data = pd.read_csv('../../data/mbl_2016/MBL_fc_data.csv')\n",
    "\n",
    "# Let's first try to do the regression using only one RBS and one operator\n",
    "rbs = data[(data.strain=='1027') & (data.epsilon_r==-13.9)]\n",
    "\n",
    "plt.figure()\n",
    "for date in rbs.date.unique():\n",
    "    plt.plot(rbs[rbs.date==date].IPTG, rbs[rbs.date==date].fold_change, 'o',\n",
    "            label=str(date))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('[IPTG] (mM)')\n",
    "plt.ylabel('fold-change')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the posterior distribution\n",
    "\n",
    "Before computing the MAP and doing the proper regression, let's look at the posterior itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter values to plot\n",
    "ea = np.linspace(1.1, 1.9, 100)\n",
    "ei = np.linspace(6.9, 7.2, 100)\n",
    "\n",
    "# make a grid to plot\n",
    "ea_grid, ei_grid = np.meshgrid(ea, ei)\n",
    "\n",
    "# compute the log posterior\n",
    "indep_var = rbs[['IPTG', 'repressors', 'epsilon_r']]\n",
    "dep_var = rbs.fold_change\n",
    "\n",
    "log_posterior = np.empty_like(ea_grid)\n",
    "for j in range(len(ea)):\n",
    "    for i in range(len(ei)):\n",
    "        log_posterior[i, j] = log_post([ea_grid[i, j], ei_grid[i, j]],\n",
    "                                       indep_var.values, dep_var.values)\n",
    "\n",
    "# Get things to scale better\n",
    "log_posterior -= log_posterior.max()\n",
    "\n",
    "# plot the results\n",
    "plt.figure()\n",
    "plt.contourf(ea_grid, ei_grid, np.exp(log_posterior), alpha=0.7,\n",
    "             cmap=plt.cm.Blues)\n",
    "plt.xlabel(r'$\\epsilon_A$')\n",
    "plt.ylabel(r'$\\epsilon_I$')\n",
    "plt.title('Posterior probability, O2 - RBS1027')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the MAP\n",
    "\n",
    "In order to compute the Maximum a posteriori parameters or MAP for short we will use the `scipy.optimize.leastsq()` function.\n",
    "For this we need to define a function that computes the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resid(param, indep_var, dep_var):\n",
    "    '''\n",
    "    Residuals for the theoretical fold change.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    param : array-like.\n",
    "        param[0] = epsilon_a\n",
    "        param[1] = epsilon_i\n",
    "    indep_var : n x 3 array.\n",
    "        series of independent variables to compute the theoretical fold-change.\n",
    "        1st column : IPTG concentration\n",
    "        2nd column : repressor copy number\n",
    "        3rd column : repressor binding energy\n",
    "    dep_var : array-like\n",
    "        dependent variable, i.e. experimental fold-change. Then length of this\n",
    "        array should be the same as the number of rows in indep_var.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fold-change_exp - fold-change_theory\n",
    "    '''\n",
    "    # unpack parameters\n",
    "    ea, ei = param\n",
    "    \n",
    "    # unpack independent variables\n",
    "    IPTG, R, epsilon_r = indep_var[:, 0], indep_var[:, 1], indep_var[:, 2]\n",
    "    \n",
    "    # compute the theoretical fold-change\n",
    "    fc_theory = fold_change(IPTG, ea, ei, 4.5, R, epsilon_r)\n",
    "    \n",
    "    # return the log posterior\n",
    "    return dep_var - fc_theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the most likely parameters we need to provide an initial guess. The optimization routine only finds a local maximum and is not in general guaranteed to converge. Therefore, the initial guess can be very important.\n",
    "\n",
    "After that we will be ready to use `scipy.optimize.leastsq()` to compute the MAP. We uses the args kwarg to pass in the other arguments to the resid() function. In our case, these arguments are the data points. The `leastsq()` function returns multiple values, but the first, the optimal parameter values (the MAP), is all we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initial guess\n",
    "p0 = np.array([1, 7]) # From plotting the posterior\n",
    "\n",
    "# Extra arguments given as tuple \n",
    "args = (indep_var.values, dep_var.values)\n",
    "\n",
    "# Compute the MAP \n",
    "popt, _ = scipy.optimize.leastsq(resid, p0, args=args)\n",
    "\n",
    "# Extract the values\n",
    "ea, ei = popt\n",
    "\n",
    "# Print results\n",
    "print(\"\"\"\n",
    "The most probable parameters for the MWC model\n",
    "----------------------------------------------\n",
    "Ka = {0:.2f} mM\n",
    "Ki = {1:.5f} mM\n",
    "\"\"\".format(np.exp(-ea), np.exp(-ei)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show that these parameters indeed give a good fit let's plot the theory and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IPTG = np.logspace(-4, np.log10(5), 200)\n",
    "fc_theory = fold_change(IPTG, ea, ei, 4.5, R=130, epsilon_r=-13.9)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(IPTG, fc_theory, '-b', label='best parameter fit')\n",
    "for date in rbs.date.unique():\n",
    "    plt.plot(rbs[rbs.date==date].IPTG, rbs[rbs.date==date].fold_change, 'o',\n",
    "            label=str(date))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('[IPTG] (mM)')\n",
    "plt.ylabel('fold-change')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing error bars on the parameters.\n",
    "\n",
    "In order to get a **credible region** on our parameter estimate we will use an aproximation in which the posterior probability can be represented as a Gaussian distribution. This approximation can be justified as a truncated Taylor expansion as follows:\n",
    "Given our log posterior distribution with parameters $\\mathbf{\\epsilon} = (\\epsilon_A, \\epsilon_I)$ we can perform a Taylor expansion around our MAP $\\epsilon^*$\n",
    "\\begin{equation}\n",
    "\\ln P(\\mathbf{\\epsilon} \\mid D, I) \\approx \\text{constant} + \\frac{1}{2} \\left(  \\mathbf{\\epsilon - \\epsilon^*}\\right)^T \\cdot H \\cdot \\left(\\mathbf{\\epsilon - \\epsilon^*}\\right),\n",
    "\\end{equation}\n",
    "where $H$ is the symmetric **Hessian matrix** whose entries are given by the second derivatives, i.e.\n",
    "\\begin{equation}\n",
    "H_{ij} = \\frac{\\partial ^2 \\ln P(\\mathbf{\\epsilon} \\mid D, I)}{\\partial \\epsilon_i \\partial \\epsilon_j} \\biggr\\rvert_{\\mathbf{\\epsilon} = \\mathbf{\\epsilon^*}}.\n",
    "\\end{equation}\n",
    "\n",
    "If we exponentiate this truncated expansion to remove the log we find something that remarkably resembles a multivariate Gaussian distribution\n",
    "\\begin{equation}\n",
    "P(\\mathbf{\\epsilon} \\mid D, I) \\approx \\text{constant} \\cdot \\exp \\left[ \\frac{1}{2} \\left( \\mathbf{\\epsilon} - \\mathbf{\\epsilon^*} \\right)^T \\cdot H \\cdot \\left( \\mathbf{\\epsilon} - \\mathbf{\\epsilon^*} \\right) \\right].\n",
    "\\end{equation}\n",
    "\n",
    "From this we can see that the Hessian matrix plays the role of the negative inverse **covariance matrix**. As a matter of fact since the second derivatives are evaluated at the MAP the Hessian is *positive definite* and therefore this matrix can be inverted, obtaining our desired covariance matrix. So if we compute the Hessian at the MAP, and then invert this matrix, the diagonal terms of this inverted matrix will be the error bars for our parameters under this Gaussian approximation of the posterior!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the covariance matrix. For this we will numerically compute the Hessian using the `numdifftools` package. We first have to initialize a `ndt.Hessian` object and then indicate where to evaluate the second derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate a numdifftools Hessian object for the log posterior\n",
    "hes_fun = ndt.Hessian(log_post)\n",
    "\n",
    "# Compute the Hessian at the map\n",
    "hes = hes_fun(popt, indep_var.values, dep_var.values)\n",
    "\n",
    "hes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we computed the Hessian let's compute the negative inverse to get our precious covariance matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the covariance matrix\n",
    "cov = -np.linalg.inv(hes) \n",
    "\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the diagonal terms of this matrix give the approximate variance in the regression parameters. The offdiagonal terms give the covariance, which describe how parameters relate to each other. From the plot of the posterior previously we saw that there is definitely a positive correlation between the parameters, and that is reflected by non-zero entries in these offdiagonal terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But recall that this is giving the error bar on $\\epsilon_A$ and $\\epsilon_I$, not the dissociation constants themselves. Therefore we must \"propagate the error\" properly by doing the proper change of variables.\n",
    "For this we use the approximation that if the error on $\\epsilon_A$ is given by $\\delta \\epsilon_A$, we can use this relationship to compute $\\delta K_A$, the error on the dissociation constant.\n",
    "\n",
    "First we know the relationshipt between $\\epsilon_A$ and $K_A$ is\n",
    "\\begin{equation}\n",
    "\\epsilon_A = - \\ln K_A.\n",
    "\\end{equation}\n",
    "Differenciating both sides we obtain\n",
    "\\begin{equation}\n",
    "\\delta \\epsilon_A = - \\frac{1}{K_A} \\delta K_A.\n",
    "\\end{equation}\n",
    "We now squre both sides and take the expected value\n",
    "\\begin{equation}\n",
    "\\langle \\delta \\epsilon_A \\rangle^2 = \\frac{\\langle \\delta K_A\\rangle^2}{K_A^2}.\n",
    "\\end{equation}\n",
    "Finally we re-arrange terms to find that the error bar on the dissociation constant is given by\n",
    "\\begin{equation}\n",
    "\\delta K_A = \\sqrt{\\langle \\delta K_A \\rangle^2} = \\sqrt{\\langle \\delta \\epsilon_A \\rangle^2 \\cdot K_A^2} = \\delta \\epsilon_A \\cdot K_A\n",
    "\\end{equation}\n",
    "\n",
    "Now let's report the parameter values with the proper error bars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the values for the dissociation constants and their respective error bars\n",
    "Ka = np.exp(-ea)\n",
    "Ki = np.exp(-ei)\n",
    "deltaKa = np.sqrt(cov[0,0]) * Ka\n",
    "deltaKi = np.sqrt(cov[1,1]) * Ki\n",
    "\n",
    "# Print results\n",
    "print(\"\"\"\n",
    "The most probable parameters for the MWC model\n",
    "----------------------------------------------\n",
    "Ka = {0:.2f} +- {1:0.3f} mM\n",
    "Ki = {2:.5f} +- {3:0.6f} mM\n",
    "\"\"\".format(Ka, deltaKa, Ki, deltaKi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the parameters to predict other strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given this result let's plot all the curves using this parameters.\n",
    "colors = sns.color_palette(n_colors=8)\n",
    "\n",
    "df_O2 = data.groupby('epsilon_r').get_group(-13.9)\n",
    "plt.figure()\n",
    "for i, strain in enumerate(df_O2[(df_O2.strain!='auto') & \\\n",
    "        (df_O2.strain!='delta')].strain.unique()):\n",
    "    # plot the theory using the parameters from the fit.\n",
    "    plt.plot(IPTG, fold_change(IPTG, \n",
    "        ea=ea, ei=ei, epsilon=4.5,\n",
    "        R=df_O2[(df_O2.strain == strain)].repressors.unique(),\n",
    "        epsilon_r=-13.9),\n",
    "        color=colors[i])\n",
    "    # plot the experimental data\n",
    "    plt.plot(df_O2[df_O2.strain == strain].sort_values(by='IPTG').IPTG, \n",
    "            df_O2[df_O2.strain == strain].sort_values(by='IPTG').fold_change, \n",
    "            marker='o', linewidth=0, label=strain, color=colors[i])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('IPTG (mM)')\n",
    "plt.ylabel('fold-change')\n",
    "plt.ylim([-0.01, 1])\n",
    "plt.legend(loc=0, ncol=3)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given this result let's plot all the curves using this parameters.\n",
    "colors = sns.color_palette(n_colors=8)\n",
    "\n",
    "df_O1 = data.groupby('epsilon_r').get_group(-15.3)\n",
    "plt.figure()\n",
    "for i, strain in enumerate(df_O1[(df_O1.strain!='auto') & \\\n",
    "        (df_O1.strain!='delta')].strain.unique()):\n",
    "    # plot the theory using the parameters from the fit.\n",
    "    plt.plot(IPTG, fold_change(IPTG, \n",
    "        ea=ea, ei=ei, epsilon=4.5,\n",
    "        R=df_O1[(df_O1.strain == strain)].repressors.unique(),\n",
    "        epsilon_r=-15.3),\n",
    "        color=colors[i])\n",
    "    # plot the experimental data\n",
    "    plt.plot(df_O1[df_O1.strain == strain].sort_values(by='IPTG').IPTG, \n",
    "            df_O1[df_O1.strain == strain].sort_values(by='IPTG').fold_change, \n",
    "            marker='o', linewidth=0, label=strain, color=colors[i])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('IPTG (mM)')\n",
    "plt.ylabel('fold-change')\n",
    "plt.ylim([-0.01, 1])\n",
    "plt.legend(loc=0, ncol=3)\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
